
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(tidyr)
library(janitor)
library(lubridate)
library(rstanarm)
library(gt)
library(gtsummary)
library(broom.mixed)

```

```{r age, echo = FALSE}
age <- read_csv("../Data/boroughs-by-age.csv",
      col_types = cols(.default = col_double(),
                       group = col_character()))
  
# It was difficult to work this data because the initial dataset was very wide.
# Therefore, I decided to make the data longer, which was difficult!

age_long <- pivot_longer(data = age, 
                         cols = -group, 
                         names_to = "county",
                         values_to = "count") %>% 
  separate(col = county, into = c("location", "type"), sep = "_", extra = "merge") %>%
  slice(1:150) %>%
  group_by(group, type, location) %>%
  summarize(av = mean(count), .groups = "drop") %>%
  arrange(location) %>%
  mutate(selected_variable = rep("age", 150))

# Originally, I set extra = drop as I was getting an error. This error was
# occurring because there were multiple words separated by "_". By dropping the
# rest of the information past the first "_", I realized that I was losing
# valuable information. Using extra = merge will display all of the latter
# information and help me preserve crucial data.

# I worked with Ishan to understand how to split the column that had both the
# county and the type of test into two columns. I first tried to map an
# str_split function but that did not give me the result I wanted. Then, I
# learned about the separate function and tried to map it as well, which created
# an error. Then, I learned that the separate function does not need a map
# function!

saveRDS(age_long, file = "age_long.RDS")



```

```{r race, echo = FALSE}

sex <- read_csv("../Data/boroughs-by-sex.csv",
      col_types = cols(.default = col_double(),
                       group = col_character()))
  
sex_long <- pivot_longer(data = sex, 
                         cols = -group, 
                         names_to = "county",
                         values_to = "count") %>% 
  separate(col = county, into = c("location", "type"), sep = "_", extra = "merge") %>%
  filter(group != "Boroughwide") %>%
  group_by(group, type, location) %>%
  summarize(av = mean(count), .groups = "drop") %>%
  mutate(selected_variable = rep("sex", 60))

saveRDS(sex_long, file = "sex_long.RDS")

```

```{r race}

race <- read_csv("../Data/boroughs-by-race.csv",
      col_types = cols(.default = col_double(),
                       group = col_character()))
  
race_long <- pivot_longer(data = race, 
                         cols = -group, 
                         names_to = "county",
                         values_to = "count") %>% 
  separate(col = county, into = c("location", "type"), sep = "_", extra = "merge") %>%
  group_by(group, type, location) %>%
  summarize(av = mean(count), .groups = "drop") %>%
  mutate(selected_variable = rep("race", 120))

saveRDS(race_long, file = "race_long.RDS")

# I followed the same workflow from the other section so that I could wrangle
# the data such that I can merge them in a way conducive to creating a dodged
# barplot that can be selected for various variables.

```

```{r merge}

joined_data <- full_join(age_long, race_long, by = c("group", "type", "location", "av", "selected_variable")) %>%
  full_join(sex_long, by = c("group", "type", "location", "av", "selected_variable")) %>%
  mutate(type = case_when(type == "CASE_COUNT" ~ "Case",
                          type == "DEATH_COUNT" ~ "Death",
                          type == "HOSPITALIZED_COUNT" ~ 
                            "Hospitalization",
                          TRUE ~ type)) %>%
  mutate(selected_variable = case_when(selected_variable == "age" ~ "Age",
                          selected_variable == "race" ~ "Race",
                          selected_variable == "sex" ~ 
                            "Sex",
                          TRUE ~ selected_variable))
  
# I decided to make and format the joined dataset in this manner so it was easy
# to link the UI to the dataset. In the UI, I have the user select either race,
# age, or sex. That is why the joined dataset has another column,
# selected_variable, to indicate that choice. I then wanted to subset each data
# to display the various groups in the graph, which is why I have the groups
# column. Then, I could use a dodged plot to display the varying data per
# county.

saveRDS(joined_data, file = "joined_data.RDS")

```


```{r 311_requests, echo = FALSE}

three <- read_csv("../Data/311_Service_Requests_from_2010_to_Present.csv", col_types = cols(
  .default = col_character(),
  `Unique Key` = col_double(),
  `Incident Zip` = col_double(),
  `Address Type` = col_logical(),
  `Facility Type` = col_logical(),
  `Due Date` = col_logical(),
  BBL = col_double(),
  `X Coordinate (State Plane)` = col_number(),
  `Y Coordinate (State Plane)` = col_number(),
  `Vehicle Type` = col_logical(),
  `Taxi Company Borough` = col_logical(),
  `Taxi Pick Up Location` = col_logical(),
  `Bridge Highway Name` = col_logical(),
  `Bridge Highway Direction` = col_logical(),
  `Road Ramp` = col_logical(),
  `Bridge Highway Segment` = col_logical(),
  Latitude = col_double(),
  Longitude = col_double()
)) %>%
  clean_names()

group_three <- three %>%
  clean_names() %>%
  select(created_date, location_type, incident_zip, borough, location) %>%
  filter(!is.na(location_type)) %>%
  filter(!is.na(borough)) %>%
  
# This decision to remove the NA's in the location_type column was made to
# make to only evaluate known locations.
  
  mutate(location_type = case_when(location_type == "Park/Playground" ~ "Park",
                          location_type == "Street/Sidewalk" ~ "Street",
                          location_type == "Street/Curbside" ~ "Street",
                          TRUE ~ location_type)) %>%
                                   
  group_by(location_type, borough) %>%
  filter(borough != "Unspecified") %>%
  summarize(count = n(), .groups = "drop") %>%
  ggplot(aes(x = location_type, y = count, fill = borough)) +
  geom_col(position = "dodge") +
  labs(title = "Amount of Social Distancing Violations per\n Location and Borough",
       x = "Location",
       y = "Count") +
  coord_flip() +
  scale_fill_manual(name = "Borough",
                    values = c("#dde392","#afbe8f","#7d8570",
                               "#646f58","#504b3a"))

saveRDS(group_three, file = "group_three.RDS")
  
```

```{r model}

# Here I make the dataset that I will use for my model. I am relying on the
# granular data provided by the NYC data so I can have a greater power of my
# study and am going to wrangle it such that I can predict cases,
# hospitalizations, and deaths on borough.

date_data <- read_csv("../Data/boroughs-case-hosp-death.csv",
                      col_types = cols(
  DATE_OF_INTEREST = col_character(),
  MN_CASE_COUNT = col_double(),
  MN_HOSPITALIZED_COUNT = col_double(),
  MN_DEATH_COUNT = col_double(),
  QN_CASE_COUNT = col_double(),
  QN_HOSPITALIZED_COUNT = col_double(),
  QN_DEATH_COUNT = col_double(),
  BK_CASE_COUNT = col_double(),
  BK_HOSPITALIZED_COUNT = col_double(),
  BK_DEATH_COUNT = col_double(),
  BX_CASE_COUNT = col_double(),
  BX_HOSPITALIZED_COUNT = col_double(),
  BX_DEATH_COUNT = col_double(),
  SI_CASDATE_OF_INTERESTE_COUNT = col_double(),
  SI_HOSPITALIZED_COUNT = col_double(),
  SI_DEATH_COUNT = col_double()
))

mn <- date_data %>%
  select(DATE_OF_INTEREST, starts_with("MN")) %>%
  mutate(...location = "MN") %>%
  rename(...date = DATE_OF_INTEREST)

names(mn) <- substring(names(mn), 4, 21)

# Rewrite the names of the dataset to eliminate the borough indicator

qn <- date_data %>%
  select(DATE_OF_INTEREST, starts_with("QN")) %>%
  mutate(...location = "QN") %>%
  rename(...date = DATE_OF_INTEREST)

names(qn) <- substring(names(qn), 4, 21)

bk <- date_data %>%
  select(DATE_OF_INTEREST, starts_with("BK")) %>%
  mutate(...location = "BK") %>%
   rename(...date = DATE_OF_INTEREST)

names(bk) <- substring(names(bk), 4, 21)


si <- date_data %>%
  select(DATE_OF_INTEREST, starts_with("SI")) %>%
  mutate(...location = "SI") %>%
  rename(...date = DATE_OF_INTEREST)

names(si) <- substring(names(si), 4, 21)


bx <- date_data %>%
  select(DATE_OF_INTEREST, starts_with("BX")) %>%
  mutate(...location = "BX") %>%
  rename(...date = DATE_OF_INTEREST)

names(bx) <- substring(names(bx), 4, 21)

# Repeating to get all of the boroughs

join <- bind_rows(bx, mn, qn, si, bk) %>%
  clean_names()

# joined dataset to help me predict the model

# Now I want to format my three dataset for joining it with my previous
# dataset.

daily_counts <- three %>%
  mutate(created_date = str_sub(created_date, 1, 10)) %>%
  mutate(borough = case_when(borough == "QUEENS" ~ "QN",
                             borough == "BRONX" ~ "BX",
                             borough == "MANHATTAN" ~ "MN",
                             borough == "BROOKLYN" ~ "BK",
                             borough == "STATEN ISLAND" ~ "SI")) %>%
  group_by(created_date, borough) %>%
  summarize(violations = n(), .groups = "drop") %>%
  rename(date = created_date,
         location = borough)

# This will summarize the number of social distancing violation counts per day
# per county for merging with the other dataset.

new_join <- inner_join(join, daily_counts, by = c("date", "location")) %>%
  drop_na()

# I chose to do an inner join so that I would capture only rows from both
# datasets that were matching to avoid dropping NAs later. This inner join still
# creates a dataset that is 734 observations long, significant enough to draw
# conclusions from.

# Now I will utilize this joined dataset to make stan_glm models.

# I want to create a table that will infer how accurate my linear model will be
# based on a linear predictive model. This will accompany my model information.

 correlations <- new_join %>%
  group_by(location) %>%
  summarise(case_correlation = cor(case_count, violations), hosp_correlation = cor(hospitalized_count, violations), death_correlation = cor(death_count, violations), .groups = "drop") %>%
  gt() %>%
  tab_header(title = "Coronavirus Metric Correlation with Daily Social Distancing Violations",
    subtitle = "Arranged by Borough") %>%
  cols_label(location = "Borough",
    case_correlation = "Case Count Correlation",
    hosp_correlation = "Hospitalization Correlation",
    death_correlation = "Death Correlation") %>%
  summary_rows(columns = vars("case_correlation", "hosp_correlation", "death_correlation"),
    fns = list(average = "mean"))
 

gtsave(correlations, filename = "joined_table1.html")

# Making a model for predicting cases

fit_case <- stan_glm(data = new_join,
                case_count ~ location + violations - 1,
                refresh = 0)

case_table <- fit_case %>%
  tbl_regression() %>%
  as_gt() %>%
  tab_header(title = md("**Regression of Covid-19 Case Counts**"),
             subtitle = "The Effect of Location and Social Distancing Violations on Covid-19 Case Counts") 

gtsave(case_table, filename = "case_table.html")

# Making a model for predicting hospitalizations

fit_hosp <- stan_glm(data = new_join,
                hospitalized_count ~ location + violations - 1,
                refresh = 0)

hosp_table <- fit_hosp %>%
  tbl_regression() %>%
  as_gt() %>%
  tab_header(title = md("**Regression of Covid-19 Hospitalizations**"),
             subtitle = "The Effect of Location and Social Distancing Violations on Covid-19 Hospitalizations") 

gtsave(hosp_table, filename = "hospe_table.html")

# Making a model for predicting deaths

fit_death <- stan_glm(data = new_join,
                death_count ~ location + violations - 1,
                refresh = 0)

death_table <- fit_death %>%
  tbl_regression() %>%
  as_gt() %>%
  tab_header(title = md("**Regression of Covid-19 Deaths**"),
             subtitle = "The Effect of Location and Social Distancing Violations on Covid-19 Deaths") 

gtsave(death_table, filename = "death_table.html")


```

